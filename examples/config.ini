[0]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model0/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[1]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model1/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[2]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model2/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[3]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model3/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[4]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model4/
learning_rate = 0.1
hidden_size = 256
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[5]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model5/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[6]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model6/
learning_rate = 0.01
hidden_size = 1024
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[7]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model7/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[8]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model8/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[9]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model9/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[10]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model10/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[11]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model11/
learning_rate = 0.1
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[12]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model12/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[13]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model13/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[14]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model14/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[15]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model15/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[16]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model16/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[17]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model17/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[18]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model18/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[19]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model19/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[20]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model20/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[21]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model21/
learning_rate = 0.001
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[22]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model22/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[23]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model23/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[24]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model24/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[25]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model25/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[26]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model26/
learning_rate = 0.001
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[27]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model27/
learning_rate = 0.1
hidden_size = 512
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[28]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model28/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[29]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model29/
learning_rate = 0.1
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[30]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model30/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[31]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model31/
learning_rate = 0.1
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[32]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model32/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[33]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model33/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[34]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model34/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[35]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model35/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[36]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model36/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[37]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model37/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[38]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model38/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[39]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model39/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[40]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model40/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[41]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model41/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[42]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model42/
learning_rate = 0.1
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[43]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model43/
learning_rate = 0.01
hidden_size = 512
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[44]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model44/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[45]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model45/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[46]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model46/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[47]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model47/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[48]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model48/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[49]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model49/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[50]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model50/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[51]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model51/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[52]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model52/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[53]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model53/
learning_rate = 0.01
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[54]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model54/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[55]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model55/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[56]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model56/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[57]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model57/
learning_rate = 0.01
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[58]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model58/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[59]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model59/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[60]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model60/
learning_rate = 0.1
hidden_size = 512
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[61]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model61/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[62]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model62/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[63]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model63/
learning_rate = 0.01
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[64]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model64/
learning_rate = 0.1
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[65]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model65/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[66]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model66/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[67]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model67/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[68]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model68/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[69]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model69/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[70]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model70/
learning_rate = 0.1
hidden_size = 256
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[71]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model71/
learning_rate = 0.001
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[72]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model72/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[73]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model73/
learning_rate = 0.1
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[74]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model74/
learning_rate = 0.1
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[75]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model75/
learning_rate = 0.01
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[76]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model76/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[77]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model77/
learning_rate = 0.01
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[78]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model78/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[79]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model79/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[80]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model80/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[81]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model81/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[82]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model82/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[83]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model83/
learning_rate = 0.1
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[84]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model84/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[85]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model85/
learning_rate = 0.1
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[86]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model86/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[87]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model87/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[88]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model88/
learning_rate = 0.001
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[89]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model89/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[90]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model90/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[91]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model91/
learning_rate = 0.001
hidden_size = 512
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[92]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model92/
learning_rate = 0.1
hidden_size = 256
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[93]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model93/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[94]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model94/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[95]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model95/
learning_rate = 0.001
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[96]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model96/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[97]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model97/
learning_rate = 0.01
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[98]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model98/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[99]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model99/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[100]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model100/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[101]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model101/
learning_rate = 0.001
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[102]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model102/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[103]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model103/
learning_rate = 0.1
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[104]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model104/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[105]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model105/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[106]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model106/
learning_rate = 0.1
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[107]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model107/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[108]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model108/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[109]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model109/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[110]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model110/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[111]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model111/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[112]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model112/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[113]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model113/
learning_rate = 0.1
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[114]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model114/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[115]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model115/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[116]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model116/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[117]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model117/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[118]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model118/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[119]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model119/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[120]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model120/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[121]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model121/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[122]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model122/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[123]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model123/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[124]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model124/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[125]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model125/
learning_rate = 0.001
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[126]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model126/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[127]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model127/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[128]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model128/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[129]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model129/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[130]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model130/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[131]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model131/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[132]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model132/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[133]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model133/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[134]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model134/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[135]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model135/
learning_rate = 0.001
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[136]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model136/
learning_rate = 0.01
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[137]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model137/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[138]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model138/
learning_rate = 0.1
hidden_size = 256
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[139]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model139/
learning_rate = 0.1
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[140]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model140/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[141]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model141/
learning_rate = 0.1
hidden_size = 256
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[142]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model142/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[143]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model143/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[144]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model144/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[145]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model145/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[146]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model146/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[147]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model147/
learning_rate = 0.01
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[148]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model148/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[149]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model149/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[150]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model150/
learning_rate = 0.01
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[151]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model151/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[152]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model152/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[153]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model153/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[154]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model154/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[155]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model155/
learning_rate = 0.01
hidden_size = 512
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[156]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model156/
learning_rate = 0.01
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[157]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model157/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[158]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model158/
learning_rate = 0.1
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[159]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model159/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[160]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model160/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[161]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model161/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[162]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model162/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[163]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model163/
learning_rate = 0.01
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0.4
embedding_size = 200

[164]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model164/
learning_rate = 0.1
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[165]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model165/
learning_rate = 0.1
hidden_size = 512
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[166]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model166/
learning_rate = 0.01
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[167]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model167/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[168]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model168/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[169]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model169/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[170]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model170/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[171]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model171/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[172]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model172/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.2
embedding_size = 200

[173]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model173/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[174]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model174/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[175]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model175/
learning_rate = 0.01
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[176]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model176/
learning_rate = 0.01
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[177]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model177/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[178]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model178/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[179]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model179/
learning_rate = 0.1
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[180]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model180/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[181]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model181/
learning_rate = 0.1
hidden_size = 1024
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[182]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model182/
learning_rate = 0.01
hidden_size = 512
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.2
embedding_size = 400

[183]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model183/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0
embedding_size = 400

[184]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model184/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[185]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model185/
learning_rate = 0.01
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[186]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model186/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0.4
embedding_size = 400

[187]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model187/
learning_rate = 0.01
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[188]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model188/
learning_rate = 0.001
hidden_size = 256
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[189]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model189/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[190]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model190/
learning_rate = 0.1
hidden_size = 512
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

[191]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model191/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.2
drop_out = 0.4
weight_decay = 0.2
embedding_size = 200

[192]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model192/
learning_rate = 0.001
hidden_size = 1024
n_layers = 2
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[193]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model193/
learning_rate = 0.001
hidden_size = 512
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 200

[194]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model194/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.2
drop_out = 0.2
weight_decay = 0.4
embedding_size = 400

[195]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model195/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[196]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model196/
learning_rate = 0.001
hidden_size = 256
n_layers = 1
batch_size = 32
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.4
embedding_size = 200

[197]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model197/
learning_rate = 0.01
hidden_size = 512
n_layers = 2
batch_size = 128
teacher_forcing_rate = 0
drop_out = 0.2
weight_decay = 0
embedding_size = 200

[198]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model198/
learning_rate = 0.001
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.4
weight_decay = 0
embedding_size = 400

[199]
train = data/nucle/train/data_p.txt
dev = data/nucle/dev/data_p.txt
expt = ./experiment/nucle/model199/
learning_rate = 0.01
hidden_size = 1024
n_layers = 1
batch_size = 64
teacher_forcing_rate = 0.4
drop_out = 0.2
weight_decay = 0.2
embedding_size = 400

